name: Main branch test package

# triggers for the workflow
on:
  workflow_dispatch:
  push:
    branches:
      - main

env:
  # These are configured in GitHub secrets
  DBT_PROFILES_DIR: ${{ github.workspace }}/integration_test_project
  DBT_ENV_SECRET_SNOWFLAKE_TEST_ACCOUNT: ${{ secrets.SNOWFLAKE_TEST_ACCOUNT }}
  DBT_ENV_SECRET_SNOWFLAKE_TEST_USER: ${{ secrets.SNOWFLAKE_TEST_USER }}
  DBT_ENV_SECRET_SNOWFLAKE_TEST_PASSWORD: ${{ secrets.SNOWFLAKE_TEST_PASSWORD }}
  DBT_ENV_SECRET_SNOWFLAKE_TEST_ROLE: ${{ secrets.SNOWFLAKE_TEST_ROLE }}
  DBT_ENV_SECRET_SNOWFLAKE_TEST_DATABASE: ${{ secrets.SNOWFLAKE_TEST_DATABASE }}
  DBT_ENV_SECRET_SNOWFLAKE_TEST_WAREHOUSE: ${{ secrets.SNOWFLAKE_TEST_WAREHOUSE }}
  DBT_ENV_SECRET_DATABRICKS_HOST: ${{ secrets.DATABRICKS_HOST }}
  DBT_ENV_SECRET_DATABRICKS_HTTP_PATH: ${{ secrets.DATABRICKS_HTTP_PATH }}
  DBT_ENV_SECRET_DATABRICKS_TOKEN: ${{ secrets.DATABRICKS_TOKEN }}
  DBT_ENV_SECRET_GCP_PROJECT: ${{ secrets.GCP_PROJECT }}
  # Env vars to test invocations model
  DBT_CLOUD_PROJECT_ID: 123
  DBT_CLOUD_JOB_ID: ABC
  DBT_CLOUD_RUN_REASON: "String with 'quotes' !"
  TEST_ENV_VAR_1: TEST_VALUE
  TEST_ENV_VAR_NUMBER: 3
  TEST_ENV_VAR_EMPTY: ""
  TEST_ENV_VAR_WITH_QUOTE: "Triggered via Apache Airflow by task 'trigger_dbt_cloud_job_run' in the airtable_ingest DAG."
  DBT_ENV_CUSTOM_ENV_FAVOURITE_DBT_PACKAGE: dbt_artifacts

jobs:
  integration:
    strategy:
      matrix:
        warehouse: ["snowflake", "bigquery", "postgres"]
        version: ["1_3_0", "1_4_0", "1_5_0", "1_6_0", "1_7_0", "1_8_0", "1_9_0"]
    runs-on: ubuntu-latest
    permissions:
      contents: "read"
      id-token: "write"

    services:
      postgres:
        image: postgres
        env:
          POSTGRES_PASSWORD: postgres
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 5432:5432

    steps:
      - name: Checkout
        uses: actions/checkout@v3

      - uses: actions/setup-python@v4
        with:
          python-version: "3.9.x"
          architecture: "x64"

      - name: Install tox
        run: python3 -m pip install tox

      - name: Install SQL Server
        run: docker run -e "ACCEPT_EULA=Y" -e "MSSQL_SA_PASSWORD=123" -p 1433:1433 -d mcr.microsoft.com/mssql/server:2022-latest

      - name: Install Microsoft ODBC
        run: sudo ACCEPT_EULA=Y apt-get install msodbcsql18 -y

      - id: auth
        if: ${{ matrix.warehouse == 'bigquery' }}
        uses: google-github-actions/auth@v1
        with:
          workload_identity_provider: ${{ secrets.GCP_WORKLOAD_IDENTITY_PROVIDER }}
          service_account: ${{ secrets.GCP_SERVICE_ACCOUNT }}

      - name: Run ${{ matrix.warehouse }} Tests
        env:
          DBT_VERSION: ${{ matrix.version }}
        run: tox -e integration_${{ matrix.warehouse }}_${{ matrix.version }}

  # Databricks doesn't like the matrix strategy, so moving back to the old integration testing without versioning
  # integration-databricks:
  #   runs-on: ubuntu-latest

  #   steps:
  #     - name: Checkout
  #       uses: actions/checkout@v3

  #     - uses: actions/setup-python@v4
  #       with:
  #         python-version: '3.8.x'
  #         architecture: 'x64'

  #     - name: Install tox
  #       run: python3 -m pip install tox

  #     - name: Run Databricks Tests
  #       run: tox -e integration_databricks

  integration-sqlserver:
    strategy:
      fail-fast: false # Don't fail one DWH if the others fail
      matrix:
        # When supporting a new version, update the list here
        version: ["1_3_0", "1_4_0", "1_7_0", "1_8_0"]
    runs-on: ubuntu-latest
    environment:
      name: Approve Integration Tests

    steps:
    - uses: actions/setup-python@v4
      with:
        python-version: "3.9.x"
        architecture: "x64"
    - name: Install SQL Server
      uses: Particular/install-sql-server-action@v1.2.0
      with:
        connection-string-env-var: SQL_SERVER_CONNECTION_STRING
        catalog: dbt_artifact_integrationtests
    - name: Create DBT User
      shell: pwsh
      run: |
          echo "Create dbt login with sysadmin"
          sqlcmd -Q "CREATE LOGIN dbt WITH PASSWORD = '123', CHECK_POLICY = OFF, CHECK_EXPIRATION = OFF" -d "dbt_artifact_integrationtests"
          sqlcmd -Q "ALTER SERVER ROLE sysadmin ADD MEMBER dbt" -d "dbt_artifact_integrationtests"
    - name: Install tox
      run: python3 -m pip install tox

    - name: Install Microsoft ODBC
      run: sudo ACCEPT_EULA=Y apt-get install msodbcsql18 -y

    - name: Checkout
      uses: actions/checkout@v3
      with:
        ref: ${{ github.event.pull_request.head.sha }} # Check out the code of the PR

    - name: Run Tests on PR
      env:
        DBT_VERSION: ${{ matrix.version }}
      run: tox -e integration_sqlserver_${{ matrix.version }}
